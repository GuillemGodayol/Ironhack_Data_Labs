{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "\n",
    "Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics.\n",
    "\n",
    "We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now take a look at the shapes of the X and y matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's pick one entry and see what number is written. Use indexing to pick the 36000th digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 149.,\n",
       "       255., 184.,  12.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  11., 133., 212., 253., 253., 253., 102.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 162., 236., 253., 253.,\n",
       "       253., 253., 253.,  55.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        35., 196., 253., 253., 253., 253., 253., 253., 239.,  18.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  89., 249., 253., 253., 253., 185.,\n",
       "       253., 253., 177.,  24.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 129.,\n",
       "       247., 253., 253., 165., 150., 205., 253., 139.,   3.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  89., 247., 253., 240., 131.,  85., 221.,\n",
       "       253., 253.,  84.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 187.,\n",
       "       253., 253., 236., 139., 252., 253., 253., 253.,  84.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  21., 253., 253., 253., 253., 253., 253.,\n",
       "       253., 253., 248.,  53.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  99.,\n",
       "       253., 253., 253., 253., 253., 214., 253., 253., 179.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   4., 186., 251., 253., 249., 172.,\n",
       "       133., 253., 253., 137.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  49.,  94.,   6.,   0., 212., 253., 253.,  39.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       126., 253., 253., 197.,   6.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  27., 234., 253., 253.,  94.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       100., 253., 253., 239.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  61., 249., 253., 253.,  79.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,\n",
       "       109., 253., 253., 193.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  66., 253., 253., 253.,  30.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       147., 253., 253., 182.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  99., 248., 253., 222.,  13.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Use the *reshape(28,28)* method and *plt.imshow()* function with the parameters *cmap = matplotlib.cm.binary* and *interpolation=\"nearest\"* to make a plot of the number. Be sure to import matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = X[36000].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x127ae30d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(reshaped, cmap = plt.cm.binary, interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use indexing to see if what the plot shows matches with the outcome of the 36000th index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training and the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:60000,]\n",
    "X_test = X[60000:,]\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using np.where I will get a column with 1 if there is a 5 and a 0 if not.\n",
    "y_train_5 = np.where(y_train=='5', 1, 0)\n",
    "y_test_5 = np.where(y_test=='5',1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets train a logistic regression to predict if a number is a 5 or not. Remember to use the 'just 5s' target train array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 36000th will be 30000 as the first 6000 where for training.\n",
    "y_predicted = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the 36000th value was nine, and not a 5, getting a 0 means it is well predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 35th value is a 5. Check if it was correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_5[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we focused on 35th value of test subset, it is correctly predicted although it is \n",
    "# not a 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumb classifier\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1))[:, 0]\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets fit and predict on the testing set using our dumb classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "never_5_clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_predicted = never_5_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_confusion = confusion_matrix(y_test_5, y_predicted)\n",
    "precision = precision_score(y_test_5, y_predicted)\n",
    "recall = recall_score(y_test_5, y_predicted)\n",
    "f1_score_lr = f1_score(y_test_5, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9026,   82],\n",
       "       [ 145,  747]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010856453558505"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8374439461883408"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8680999418942476"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_confusion = confusion_matrix(y_test_5, dumb_predicted)\n",
    "dumb_precision = precision_score(y_test_5, dumb_predicted)\n",
    "dumb_recall = recall_score(y_test_5, dumb_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dumb_f1_score = f1_score(y_test_5, dumb_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9108,    0],\n",
       "       [ 892,    0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumb_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumb_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumb_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Logistic Regression model works quite good, having Precision, Recall and F1_score\n",
    "# over 0.8\n",
    "# The dumb model is not good. Taking a look at the confusion matrix and seeing there are\n",
    "# two zeros in the second column means that there are no True Positives neither \n",
    "# False Positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# second element of roc_curve is not our predictions, but probability estimates\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# the predict_proba gives us a column with the probability of having that result in each\n",
    "# row. In our case, first column will be the probability of being a 0 and the second one\n",
    "# the probability of being 1. That's why we need to choose second column of estimates.\n",
    "\n",
    "estimates = lr_model.predict_proba(X_test)[:,1]\n",
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test_5, estimates)\n",
    "\n",
    "estimates_dumb = np.zeros((len(X_test), 1))[:, 0]\n",
    "fpr_dumb, tpr_dumb, thresholds_dumb = roc_curve(y_test_5, estimates_dumb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD4CAYAAADmWv3KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXt0lEQVR4nO3dfbRVdZ3H8c93IDB8hLg2BiiYmGIq6g16WKt8asInmLISHBtrnMwSR9NaS8OncVaptZY4rbGMnszWUgTSvCbmpGk2Jcg1eTbwCqhcEW5gQCt5/s4fZx89XO/dZ9979z7nt/d5v9Zicc4++57z5fDly+/uvT/3mLsLAFA8/1DvAgAA2WDAA0BBMeABoKAY8ABQUAx4ACio/vV64aFDh/rIkSPr9fIouGefffYv7t5Uj9emt5GlnvR23Qb8yJEj1draWq+XR8GZ2Uv1em16G1nqSW9ziAYACooBDwAFxYAHgIJiwANAQTHgAaCgqg54M/uJmW0ws6XdPG5m9l0zazOzxWZ2YvplAumjt1F0SVbwd0maEPP4GZJGR78ulvT9vpcF1MRdordRYFWvg3f3p8xsZMwukyTd7aWfOzzPzA4ys0PcfV1KNaKB3TP/ZT24sL3Lx8a85wDdcM4xvX5uehshmvnMy2raf6BOO/rdfX6uNIJOwyS9UnF/bbTtbf8IzOxilVZCOvTQQ1N4aeRB3JCuZv7qTZKk8aOGpFlSUvQ2amrFa1t1fcsyfXR0k0496mCZWZ+er6ZJVnefIWmGJDU3N/NJI3XUl6HbU30Z0uNHDdGkscN0/viwhya9jb7avmu3Lp/5nA7Yp79uOffYPg93KZ0B3y5pRMX94dE2xKjlgO1KLVfGeRnSXaC3UTO3/e9K/fm1rfrxhc0aut/AVJ4zjQHfImmqmc2UNF7S5kY6RtnbQV3nQw95Hrq11NC9jdp5+sWNmvH7VTp//KGpHHsvqzrgzexeSSdLGmpmayXdIOkdkuTud0qaK+lMSW2S/i7pC6lVF5DuBnlvBzUDtv7obYRg8xs7ddWshRr5rn117VlHp/rcSa6imVLlcZd0aWoV1Um1lXh3g5xBnV+N0tsI2w0PLtX6rdv1iy9/WIMGpHtatG4/LriWkhxGqbYSZ5ADSNtDi17VLxe+qitOH62xIw5K/fkLP+Dvmf+yvvHAEknxh1EY4ABqad3mNzTtgSUaO+IgTT3liExeo5ADvnLFXl6Zf+uTxzK8AQRhzx7X12Yv0q49runnjVX/ftn8WLDCDPiuhvr4UUNYmQMIzk//uEZ/aNuomz91rEYN3Tez18n9gC8PdoY6gDxY8dpW3frrP+v0o9+tyR8YUf0L+iDXA77z8XWGOoCQZZFWjZPbAV853Dm+DiAPskirxsndgO98SIbhDiAP5q0qpVWnjEs3rRondwP+wYXtWr5uC4dkAOTGlm07ddWsRRr5rn113dnpplXj5GrA3zP/Zc1fvUnjRw3RfV/6UL3LAYBEbnhwmV7bsi2TtGqcXH0ma/kyyEljh9W5EgBI5qFFr+qB59p12alHZJJWjZOLFXz5uHv50AyHZQDkQS3SqnGCH/BdXQoJAKErp1V37s42rRon+AFfPizD1TIA8qScVv3WJ7NNq8YJ+hh85UlVhjuAvHgrrXqwpozLNq0aJ+gBz0lVAHmzd1r1uMzTqnGCP0TD6h1AntQ6rRon2BV8+fAMAORFPdKqcYId8ByeAZAn5bTqYUMGpf7Zqr0V9CEaDs8AyItyWnXOJR/SvgPDGK3BruABIC8q06onHDq43uW8iQEPAH1Q77RqnCAHPCdYAeRBCGnVOGFVE+EEK4A8KKdVrzt7TN3SqnGCHPASJ1gBhK2cVj3tqPqmVeMEO+ABIFTbd+3WFfct1P4D659WjRPGtTwAkCO3/Walnl+3RT/612Y17V/ftGocVvAA0APzVm3UjKdKadXTx9Q/rRqHAQ8ACYWYVo3DIRoASCjEtGocVvAAkMCvFpfSqlNPCSutGifRgDezCWa2wszazOzqLh4/1MyeMLPnzGyxmZ2ZfqlA+uhtJPHa5m2a9sBSHT/iIE09Nay0apyqA97M+km6Q9IZksZImmJmYzrtdq2kWe5+gqTJkr6XdqFA2uhtJFFOq+7YtUe3nzdW7wgsrRonSaXjJLW5+yp33yFppqRJnfZxSQdEtw+U9Gp6JQKZobdR1U//uEb/1/aXYNOqcZIM+GGSXqm4vzbaVulGSReY2VpJcyVd1tUTmdnFZtZqZq0dHR29KBdIFb2NWHlIq8ZJ63uNKZLucvfhks6U9HMze9tzu/sMd2929+ampqaUXhrIFL3doPKSVo2TZMC3S6r8r2t4tK3SRZJmSZK7Py1pH0lD0ygQyBC9jW6V06q3nntc0GnVOEkG/AJJo81slJkNUOlEU0unfV6WdJokmdnRKv0j4PtUhI7eRpfeSquOCD6tGqfqgHf3XZKmSnpU0vMqXVGwzMxuMrOJ0W5XSfqimS2SdK+kz7u7Z1U0kAZ6G13ZO63a+aKqfEkUxXL3uSqdYKrcdn3F7eWSPpJuaUD26G10lre0apz8XNAJABnLY1o1DgMeAJTftGocBjyAhpfntGqcYvwpAKAP7orSqteefXTu0qpxGPAAGtrK9Vt1S5RWPX9csT4HmgEPoGFt37Vbl8/Md1o1Tr6vAQKAPsjLZ6v2Fit4AA2pKGnVOAx4AA2nSGnVOByiAdBwbozSqrMLkFaNwwoeQEP51eJXdX+UVj2xAGnVOMEN+Hvmv6z5qzfVuwwABVTEtGqc4Ab8gwtLP4570tjOH6wDAL1X1LRqnCD/hONHDdH544sVOABQX0VNq8YJcsADQJqKnFaNw4AHUGg7du3RFQVOq8Yp7vVBAKBSWnX5ui36YUHTqnFYwQMorHmrNuoHT72oKeNG6OMFTavGYcADKKRGSavG4RANgEJqlLRqHFbwAArn4cXrdP9z7bq0AdKqcRjwAArltc3b9I0Hluj44QfqsgZIq8ZhwAMojD17XF+fU0qrTm+QtGqcxv7TAyiUu/64Rr9/oZRWPbxpv3qXU3cMeACF0Khp1TgMeAC518hp1TiNee0QgEJp5LRqHFbwAHJtfpRWnfyBxkyrxmHAA8itLdt26spZi3TokEG67uzGTKvG4RANgNwirRov0QrezCaY2QozazOzq7vZ57NmttzMlpnZPemWCaSPvs430qrVVf0vz8z6SbpD0sclrZW0wMxa3H15xT6jJV0j6SPu/rqZHZxVwUAa6Ot8I62aTJIV/DhJbe6+yt13SJopaVKnfb4o6Q53f12S3H1DumUCqaOvc4q0anJJ3plhkl6puL822lbpSElHmtkfzGyemU3o6onM7GIzazWz1o6Ojt5VDKQjtb6W6O1a+tnTpbTqtLNIq1aT1n99/SWNlnSypCmSfmhmB3Xeyd1nuHuzuzc3NTWl9NJAZhL1tURv18rK9Vt1yyN/1qlHHax/GU9atZokA75d0oiK+8OjbZXWSmpx953uvlrSSpX+YQChoq9zppxW3W9gf91KWjWRJAN+gaTRZjbKzAZImiyppdM+v1RplSMzG6rSt7arUqwTSBt9nTPltOot5x5HWjWhqgPe3XdJmirpUUnPS5rl7svM7CYzmxjt9qikjWa2XNITkr7u7huzKhroK/o6X0ir9k6iZIC7z5U0t9O26ytuu6Qro19ALtDX+UBatfeIfgEI2o0ty7Ru8xuafcmHSav2EBeQAgjWw4vX6f4/tWvqqaN10mGkVXuKAQ8gSKRV+44BDyA4pFXTwbsGIDikVdPBgAcQlBdIq6aGAQ8gGDt27dHlMxdq34H9dcu5x5JW7SOuOQIQjOmPldKqMz53kg7ef596l5N7rOABBGH+qo2683eltOo/HfOP9S6nEBjwAOqOtGo2OEQDoO5Iq2aDFTyAupq7JEqrnnIEadWUMeAB1M36LRVp1dP4UftpY8ADqIs9e1xfm71I23eSVs0K7yiAuiCtmj0GPICaI61aGwx4ADVFWrV2uB4JQE2RVq0dVvAAauaZ1ZtIq9YQAx5ATWzZtlNfvW8hadUa4hANgJogrVp7rOABZI60an0w4AFkirRq/TDgAWSmnFbdtnO3biOtWnO82wAyc/fTpbTqtWeN0XtJq9YcAx5AJl5Yv1U3k1atKwY8gNSRVg0D1yoBSB1p1TCwggeQqnJa9bxm0qr1xoAHkJqtUVp1xOBBuu4c0qr1xiEaAKm5sWX5m2nV/Uir1l2iFbyZTTCzFWbWZmZXx+x3rpm5mTWnVyKQHXo7PXOXrNMv/rSWtGpAqg54M+sn6Q5JZ0gaI2mKmb3tey8z21/S5ZLmp10kkAV6Oz2kVcOUZAU/TlKbu69y9x2SZkqa1MV+/yXpVknbUqwPyBK9nQLSquFK8jcxTNIrFffXRtveZGYnShrh7g/HPZGZXWxmrWbW2tHR0eNigZTR2ykop1WnkVYNTp//qzWzf5B0m6Srqu3r7jPcvdndm5uamvr60kCm6O3qymnVU97XpAtIqwYnyYBvlzSi4v7waFvZ/pLeL+lJM1sj6YOSWjgZhRygt/tgx649uuK+Ulr11k8fR1o1QEkG/AJJo81slJkNkDRZUkv5QXff7O5D3X2ku4+UNE/SRHdvzaRiID30dh9Mf2yllr26Rbd86ljSqoGqOuDdfZekqZIelfS8pFnuvszMbjKziVkXCGSF3u490qr5kCiJ4O5zJc3ttO36bvY9ue9lAbVBb/ccadX8IGoGoEdIq+YHF6wCSOyRKK16KWnVXGDAA0hk/ZZtuuaBJTpu+IH6D9KqucCAB1BVZVp1OmnV3OBvCUBVpFXziQEPIBZp1fxiwAPoFmnVfOMaJwDduj1Kq/6Az1bNJVbwALr0zOpN+n6UVv0EadVcYsADeBvSqsXAIRoAb0NatRhYwQPYC2nV4mDAA3gTadViYcADkCS5u74+ZzFp1QLhbxCAJOnup1/SUys7SKsWCAMegF5Yv1Xfmvs8adWCYcADDY60anFx/RPQ4EirFhcreKCBLVhT+mzVzzYPJ61aQAx4oEGV06rDBw/S9eccU+9ykAEO0QAN6j8fWq5X//qGZl/yIdKqBcUKHmhAjyxZpznPltOqQ+pdDjLCgAcaDGnVxsGABxoIadXGwt8u0EDeTKueeTRp1QbAgAcaRNuGUlr15Pc16YIPHlbvclADDHigAVSmVb9NWrVhcG0U0ABuf2yllraTVm00rOCBgiOt2rgY8ECBkVZtbIkGvJlNMLMVZtZmZld38fiVZrbczBab2eNmxhkcBK8R+rqcVp1+3vGkVRtQ1QFvZv0k3SHpDEljJE0xs84fs/6cpGZ3P07SHEnfTrtQIE2N0Ne/XlpKq37lZNKqjSrJCn6cpDZ3X+XuOyTNlDSpcgd3f8Ld/x7dnSdpeLplAqkrdF+v37JNV99fSqtefjpp1UaVZMAPk/RKxf210bbuXCTpka4eMLOLzazVzFo7OjqSVwmkL7W+lsLqbdKqKEv1b97MLpDULOk7XT3u7jPcvdndm5uamtJ8aSAz1fpaCqu3SauiLMlZl3ZJIyruD4+27cXMTpc0TdLH3H17OuUBmSlkX5NWRaUkK/gFkkab2SgzGyBpsqSWyh3M7ARJP5A00d03pF8mkLrC9XU5rTpoQD99+1zSqkgw4N19l6Spkh6V9LykWe6+zMxuMrOJ0W7fkbSfpNlmttDMWrp5OiAIRezr/368lFa9+VPH6eADSKsi4Y8qcPe5kuZ22nZ9xe3TU64LyFyR+nrBmk36/pOltOqE95NWRQmn14GcI62K7hBtA3KOz1ZFd1jBAzlGWhVxGPBATm3Ysk3X3L9Exw4jrYquMeCBHCqnVd8grYoYdAWQQz+f95J+F6VVjziYtCq6xoAHcqZtw1Z982HSqqiOAQ/kCGlV9ATXVAE5Uk6r3nnBSaRVURUreCAnWqO06mdOIq2KZBjwQA5s3bZTX521UMMGv1M3TCStimQ4RAPkwE0PLVf7629o1pdIqyI5VvBA4H69dJ1mR2nV5pGkVZEcAx4IGGlV9AUDHggUaVX0FR0DBKqcVv0GaVX0EgMeCFDbhr/pmw8/r48d2aTPkVZFLzHggcCU0qrPadCAfvrOp0mrove43goIDGlVpIUVPBAQ0qpIEwMeCARpVaSNQzRAIEirIm2s4IEAlNOqXz75vaRVkRoGPFBne6VVTzuy3uWgQBjwQB11TqsO6M8/SaSHbgLqiLQqssSAB+qEtCqyxoAH6mDHrj36avTZqqRVkRWuxQLq4LuPv6Al7Zt15wUnklZFZljBAzXWumaTvvdkW5RWPaTe5aDAGPBADZFWRS0lGvBmNsHMVphZm5ld3cXjA83svujx+WY2Mu1CgSzUurfLadXpnx1LWhWZqzrgzayfpDsknSFpjKQpZjam024XSXrd3Y+QNF3SrWkXCqSt1r1NWhW1lmQFP05Sm7uvcvcdkmZKmtRpn0mSfhbdniPpNOOyAISvZr1dTqu+f9gBpFVRM0kG/DBJr1TcXxtt63Ifd98labOkd3V+IjO72Mxazay1o6Ojyxcb854DNOY9ByQoC+izmvX2bncdP+Ig3U5aFTVU04OA7j5D0gxJam5u9q72ueEcTjwhf6r19iEHvlN3fWFczetCY0uylGiXNKLi/vBoW5f7mFl/SQdK2phGgUCG6G0UWpIBv0DSaDMbZWYDJE2W1NJpnxZJF0a3Py3pt+7e5QodCAi9jUKreojG3XeZ2VRJj0rqJ+kn7r7MzG6S1OruLZJ+LOnnZtYmaZNK/1CAoNHbKLpEx+Ddfa6kuZ22XV9xe5ukz6RbGpA9ehtFxul8ACgoBjwAFBQDHgAKigEPAAVl9briy8w6JL3UzcNDJf2lhuXECaWWUOqQwqklro7D3L2plsWU5aS3Q6lDCqeWUOqQUurtug34OGbW6u7N9a5DCqeWUOqQwqkllDp6IpSaQ6lDCqeWUOqQ0quFQzQAUFAMeAAoqFAH/Ix6F1AhlFpCqUMKp5ZQ6uiJUGoOpQ4pnFpCqUNKqZYgj8EDAPou1BU8AKCPGPAAUFA1H/B9+ZBjM7sm2r7CzD6RcR1XmtlyM1tsZo+b2WEVj+02s4XRr84/XjaLWj5vZh0Vr/nvFY9daGYvRL8u7Py1KdcxvaKGlWb214rHUntPzOwnZrbBzJZ287iZ2XejOheb2YkVj6X2fvSw5iD6OmEtNentUPo6YS3F7G13r9kvlX4k64uSDpc0QNIiSWM67fMVSXdGtydLui+6PSbaf6CkUdHz9MuwjlMkDYpuf7lcR3T/bzV+Tz4v6X+6+NohklZFvw+Obg/Oqo5O+1+m0o/XzeI9+aikEyUt7ebxMyU9IskkfVDS/LTfjzz2dUi9HUpfN3pv13oF35cPOZ4kaaa7b3f31ZLaoufLpA53f8Ld/x7dnafSp/1kIcl70p1PSPqNu29y99cl/UbShBrVMUXSvb18rVju/pRKP3u9O5Mk3e0l8yQdZGaHKN33oydC6etEtdSot0Pp697UUpjervWA78uHHCf52jTrqHSRSv+rlu1jpQ9Ynmdm/9zLGnpay7nRt2xzzKz8MXN1eU+ib+lHSfptxeY035Nquqs1zfcjjXq63CfDvk5aS6WsejuUvu7R8xWtt2v6odt5ZGYXSGqW9LGKzYe5e7uZHS7pt2a2xN1fzLCMhyTd6+7bzexLKq0ET83w9aqZLGmOu++u2Fbr9wR9FEBvh9bXUsF6u9Yr+L58yHGSr02zDpnZ6ZKmSZro7tvL2929Pfp9laQnJZ3QyzoS1eLuGyte/0eSTurJnyOtOipMVqdvYVN+T6rprtY034806ulynwz7OmkttejtUPq6p89XrN5O6+RBwhMM/VU6OTBKb53sOKbTPpdq75NRs6Lbx2jvk1Gr1PuTrEnqOEGlEzOjO20fLGlgdHuopBcUc8ImpVoOqbj9SUnz/K0TL6ujmgZHt4dkVUe031GS1igKyWXxnkTPM1Ldn4g6S3ufiHom7fcjj30dUm+H0teN3tuZNn43f4AzJa2MGmxatO0mlVYSkrSPpNkqnWx6RtLhFV87Lfq6FZLOyLiOxyStl7Qw+tUSbf+wpCVRkyyRdFEN3pObJS2LXvMJSUdVfO2/Re9Vm6QvZFlHdP9GSbd0+rpU3xOVVlDrJO1U6VjjRZIukXRJ9LhJuiOqc4mk5izejzz2dUi9HUpfN3Jv86MKAKCgSLICQEEx4AGgoBjwAFBQDHgAKCgGPAAUFAMeAAqKAQ8ABfX/o7UMC+cmvCIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1,2)\n",
    "\n",
    "ax[0].plot(fpr_lr, tpr_lr)\n",
    "ax[1].plot(fpr_dumb, tpr_dumb)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score for LR model is: 0.9142204359839378\n",
      "roc_auc_score for Dumb model is: 0.5\n"
     ]
    }
   ],
   "source": [
    "lr_auc = roc_auc_score(y_test_5, y_predicted)\n",
    "dumb_auc = roc_auc_score(y_test_5, dumb_predicted)\n",
    "\n",
    "print('roc_auc_score for LR model is:', lr_auc)\n",
    "print('roc_auc_score for Dumb model is:', dumb_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This metric tells us that our LR model works pretty well, while the dumb model is\n",
    "# the worst case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
